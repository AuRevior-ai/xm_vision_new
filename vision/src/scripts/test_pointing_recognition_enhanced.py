"""å¢å¼ºç‰ˆæŒ‡å‘æ‰‹åŠ¿è¯†åˆ«æµ‹è¯•è„šæœ¬

åŠŸèƒ½ï¼š
- æ‰“å¼€æ‘„åƒå¤´ï¼Œå®æ—¶æ£€æµ‹æ‰‹éƒ¨å…³é”®ç‚¹
- å½“æ£€æµ‹åˆ°â€œæŒ‡å‘â€æ‰‹åŠ¿æ—¶ï¼Œåœ¨ç”»é¢ä¸Šç”¨ç®­å¤´æ˜¾ç¤ºæŒ‡å‘æ–¹å‘
- åœ¨ç»ˆç«¯æŒç»­æ‰“å°ï¼šæ˜¯å¦æ£€æµ‹åˆ°æŒ‡å‘æ‰‹åŠ¿ã€æŒ‡å‘å‘é‡ã€æŒ‡å°–åæ ‡

é€€å‡ºæ–¹å¼ï¼šæŒ‰ä¸‹é”®ç›˜ q é”®
"""

import cv2
import numpy as np

from pointing_gesture_recognition.pointing_recognition import PointingRecognizer


def draw_pointing_direction(image, index_finger_points, color=(0, 255, 0)):
    """æ ¹æ®é£ŸæŒ‡çš„ 3 ä¸ªå…³é”®ç‚¹ï¼Œåœ¨å›¾åƒä¸Šç”»å‡ºæŒ‡å‘ç®­å¤´ã€‚

    Args:
        image: BGR å›¾åƒ
        index_finger_points: [tip, p1, p2]ï¼Œæ¯ä¸ªæ˜¯ [x, y]
        color: çº¿æ¡é¢œè‰²
    """
    if index_finger_points is None or len(index_finger_points) < 3:
        return image

    tip = tuple(index_finger_points[0])       # æŒ‡å°–
    mid = tuple(index_finger_points[1])       # ä¸­é—´å…³èŠ‚
    base = tuple(index_finger_points[2])      # è¿‘ç«¯å…³èŠ‚

    # ä»¥é£ŸæŒ‡ä¸­é—´å…³èŠ‚åˆ°æŒ‡å°–çš„æ–¹å‘ä½œä¸ºæŒ‡å‘æ–¹å‘
    dir_vec = np.array(tip) - np.array(mid)
    norm = np.linalg.norm(dir_vec)
    if norm < 1e-5:
        return image

    dir_unit = dir_vec / norm
    arrow_len = 80  # ç®­å¤´é•¿åº¦åƒç´ 
    arrow_end = (int(tip[0] + dir_unit[0] * arrow_len),
                 int(tip[1] + dir_unit[1] * arrow_len))

    # ç”»ç®­å¤´ä¸»çº¿
    cv2.arrowedLine(image, tip, arrow_end, color, 3, line_type=cv2.LINE_AA, tipLength=0.25)

    # ç”»æŒ‡å°–ã€å°åœ†ç‚¹
    cv2.circle(image, tip, 6, (0, 0, 255), -1)
    cv2.circle(image, mid, 4, (255, 0, 0), -1)
    cv2.circle(image, base, 4, (255, 0, 0), -1)

    return image


def run_pointing_recognition_enhanced(camera_index: int = 0):
    """è¿è¡Œå¢å¼ºç‰ˆæŒ‡å‘æ‰‹åŠ¿è¯†åˆ«ã€‚

    Args:
        camera_index: æ‘„åƒå¤´ç´¢å¼•ï¼Œé»˜è®¤ 0
    """
    cap = cv2.VideoCapture(camera_index)

    if not cap.isOpened():
        print(f"æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {camera_index}")
        return

    print("ğŸ“¹ å¢å¼ºç‰ˆæŒ‡å‘æ‰‹åŠ¿è¯†åˆ«å·²å¯åŠ¨ï¼ŒæŒ‰ q é€€å‡ºã€‚")

    estimator = PointingRecognizer()

    frame_count = 0
    pointing_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            print("æœªèƒ½ä»æ‘„åƒå¤´è¯»å–åˆ°å›¾åƒï¼Œç»“æŸã€‚")
            break

        frame_count += 1

        pointing_frame, detect_pointing, index_finger_points = estimator.use(frame)

        # å¦‚æœæ£€æµ‹åˆ°äº†æŒ‡å‘æ‰‹åŠ¿ï¼Œå°±åœ¨å›¾åƒä¸Šç”»ç®­å¤´
        if index_finger_points is not None:
            pointing_count += 1
            pointing_frame = draw_pointing_direction(pointing_frame, index_finger_points)

            tip = index_finger_points[0]
            p1 = index_finger_points[1]
            # è®¡ç®—æŒ‡å‘å‘é‡ï¼ˆä» p1 æŒ‡å‘ tipï¼‰
            direction_vec = np.array(tip) - np.array(p1)

            print(f"[Pointing] tip={tip}, direction_vec={direction_vec}")
        else:
            print("[No pointing gesture detected]")

        # åœ¨å·¦ä¸Šè§’æ˜¾ç¤ºç®€å•ç»Ÿè®¡ä¿¡æ¯
        info_text = f"Frames: {frame_count}  Pointing frames: {pointing_count}"
        cv2.putText(pointing_frame, info_text, (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2, cv2.LINE_AA)

        cv2.imshow("Pointing Recognition Enhanced", pointing_frame)

        key = cv2.waitKey(1) & 0xFF
        if key == ord("q"):
            break

    cap.release()
    cv2.destroyAllWindows()
    print(f"ç»“æŸã€‚æ€»å¸§æ•°: {frame_count}, æ£€æµ‹åˆ°æŒ‡å‘æ‰‹åŠ¿çš„å¸§æ•°: {pointing_count}")


if __name__ == "__main__":
    run_pointing_recognition_enhanced()
