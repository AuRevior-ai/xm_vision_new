#æ­¤è„šæœ¬ç”¨äºŽæ‰“å¼€æ‘„åƒå¤´ï¼Œæ•æ‰ä¸ªäººè„¸å›¾åƒå¹¶ä¿å­˜ï¼Œç”¨äºŽäººè„¸è¯†åˆ«æ¨¡åž‹çš„è®­ç»ƒ(å¢žå¼ºç‰ˆ)
#æ”¯æŒOpenCVæ‘„åƒå¤´å’ŒAzure Kinectæ‘„åƒå¤´é€‰æ‹©
import cv2
import numpy as np
import os
from face_identification.face_identification import FaceIdentifier
from face_identification.save_personal_faces import save_faces

def choose_camera_type():
    """é€‰æ‹©æ‘„åƒå¤´ç±»åž‹"""
    print("\nðŸŽ¥ è¯·é€‰æ‹©æ‘„åƒå¤´ç±»åž‹ï¼š")
    print("1. OpenCV æ‘„åƒå¤´ (USBæ‘„åƒå¤´/ç¬”è®°æœ¬å†…ç½®æ‘„åƒå¤´)")
    print("   ðŸ“‹ ç‰¹ç‚¹ï¼šå¿«é€Ÿå¯åŠ¨ï¼Œå…¼å®¹æ€§å¥½ï¼Œé€‚åˆå¿«é€Ÿæµ‹è¯•")
    print("   ðŸ“Š åˆ†è¾¨çŽ‡ï¼š640x480 (VGA)")
    print()
    print("2. Azure Kinect æ‘„åƒå¤´ (é«˜æ¸…æ·±åº¦æ‘„åƒå¤´)")  
    print("   ðŸ“‹ ç‰¹ç‚¹ï¼šé«˜æ¸…ç”»è´¨ï¼Œä¸“ä¸šçº§æ‘„åƒå¤´ï¼Œå›¾åƒè´¨é‡æ›´å¥½")
    print("   ðŸ“Š åˆ†è¾¨çŽ‡ï¼š720P/1080P å¯é€‰")
    print("   ðŸ’¡ å»ºè®®ï¼šç”¨äºŽé«˜è´¨é‡äººè„¸é‡‡é›†")
    
    while True:
        choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1 æˆ– 2): ").strip()
        if choice == "1":
            return "opencv"
        elif choice == "2":
            return "kinect"
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1 æˆ– 2")

def initialize_opencv_camera():
    """åˆå§‹åŒ–OpenCVæ‘„åƒå¤´"""
    print("ðŸ“¹ æ­£åœ¨åˆå§‹åŒ– OpenCV æ‘„åƒå¤´...")
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€OpenCVæ‘„åƒå¤´")
        return None
    
    # è®¾ç½®æ‘„åƒå¤´åˆ†è¾¨çŽ‡
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    print("âœ… OpenCV æ‘„åƒå¤´åˆå§‹åŒ–æˆåŠŸ")
    return cap

def initialize_kinect_camera():
    """åˆå§‹åŒ–Azure Kinectæ‘„åƒå¤´"""
    print("ðŸ“¹ æ­£åœ¨åˆå§‹åŒ– Azure Kinect æ‘„åƒå¤´...")
    try:
        # å¯¼å…¥Azure Kinectæ‘„åƒå¤´ç±»
        from camera.k4acam import AzureKinectCamera
        
        # é€‰æ‹©é¢„è®¾é…ç½®
        print("\nðŸ“‹ Azure Kinect é¢„è®¾é…ç½®ï¼š")
        print("1. balanced - å¹³è¡¡æ¨¡å¼")
        print("   ðŸ“Š åˆ†è¾¨çŽ‡ï¼š720Pï¼Œæ·±åº¦æ¨¡å¼ï¼šWFOV_2X2BINNED")
        print("   ðŸ’¡ æŽ¨èï¼šä¸€èˆ¬ç”¨é€”ï¼Œå¹³è¡¡ç”»è´¨å’Œæ€§èƒ½")
        print()
        print("2. high_quality - é«˜è´¨é‡æ¨¡å¼")
        print("   ðŸ“Š åˆ†è¾¨çŽ‡ï¼š1080Pï¼Œæ·±åº¦æ¨¡å¼ï¼šNFOV_UNBINNED") 
        print("   ðŸ’¡ æŽ¨èï¼šæœ€ä½³ç”»è´¨ï¼Œé€‚åˆé«˜è´¨é‡äººè„¸é‡‡é›†")
        print()
        print("3. fast - å¿«é€Ÿæ¨¡å¼")
        print("   ðŸ“Š åˆ†è¾¨çŽ‡ï¼š720Pï¼Œæ·±åº¦æ¨¡å¼ï¼šNFOV_2X2BINNED")
        print("   ðŸ’¡ æŽ¨èï¼šå¿«é€Ÿå“åº”ï¼Œé€‚åˆå®žæ—¶åº”ç”¨")
        
        while True:
            preset_choice = input("è¯·é€‰æ‹©é¢„è®¾ (1-3): ").strip()
            if preset_choice == "1":
                preset = "balanced"
                break
            elif preset_choice == "2":
                preset = "high_quality"
                break
            elif preset_choice == "3":
                preset = "fast"
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-3")
        
        kinect_cam = AzureKinectCamera(config_preset=preset)
        kinect_cam.start()
        print(f"âœ… Azure Kinect æ‘„åƒå¤´åˆå§‹åŒ–æˆåŠŸ (é¢„è®¾: {preset})")
        return kinect_cam
    except Exception as e:
        print(f"âŒ Azure Kinect æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥: {e}")
        print("ðŸ’¡ å»ºè®®ï¼šæ£€æŸ¥è®¾å¤‡è¿žæŽ¥æˆ–ä½¿ç”¨OpenCVæ‘„åƒå¤´")
        return None

def get_frame_from_camera(camera, camera_type):
    """ä»Žæ‘„åƒå¤´èŽ·å–å¸§"""
    if camera_type == "opencv":
        ret, frame = camera.read()
        return ret, frame
    elif camera_type == "kinect":
        try:
            # ä½¿ç”¨Azure Kinectçš„get_color_frameæ–¹æ³•
            ret, frame = camera.get_color_frame()
            return ret, frame
        except Exception as e:
            print(f"è¯»å–Kinectå¸§æ—¶å‡ºé”™: {e}")
            return False, None

def release_camera(camera, camera_type):
    """é‡Šæ”¾æ‘„åƒå¤´èµ„æº"""
    if camera_type == "opencv":
        camera.release()
    elif camera_type == "kinect":
        camera.stop()
    cv2.destroyAllWindows()

def main():
    print("äººè„¸é‡‡é›†è„šæœ¬ - å¢žå¼ºç‰ˆ")
    print("=" * 50)
    
    # é€‰æ‹©æ‘„åƒå¤´ç±»åž‹
    camera_type = choose_camera_type()
    
    # åˆå§‹åŒ–é€‰ä¸­çš„æ‘„åƒå¤´
    if camera_type == "opencv":
        camera = initialize_opencv_camera()
    else:  # kinect
        camera = initialize_kinect_camera()
    
    if camera is None:
        print("âŒ æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        return
    
    # è®¾ç½®çª—å£ - åœ¨æ˜¾ç¤ºå›¾åƒä¹‹å‰è®¾ç½®
    window_names = {
        'main': 'Face Collection',
        'face': 'Captured Face'
    }
    
    for window_name in window_names.values():
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, 800, 600)
    
    try:
        estimator = FaceIdentifier()
        print("âœ… äººè„¸è¯†åˆ«å™¨åˆå§‹åŒ–æˆåŠŸ")
        print(f"\nðŸŽ¥ å½“å‰ä½¿ç”¨æ‘„åƒå¤´ï¼š{'OpenCV æ‘„åƒå¤´' if camera_type == 'opencv' else 'Azure Kinect æ‘„åƒå¤´'}")
    except Exception as e:
        print(f"âŒ äººè„¸è¯†åˆ«å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        release_camera(camera, camera_type)
        return
    
    # ç­‰å¾…ç”¨æˆ·è¾“å…¥ï¼Œç¡®ä¿çœŸæ­£çš„äº¤äº’å¼è¾“å…¥
    print("\n" + "="*50)
    while True:
        try:
            face_owner = input("è¯·è¾“å…¥äººè„¸æ‹¥æœ‰è€…çš„åç§°ï¼ˆä¸èƒ½ä¸ºç©ºï¼‰ï¼š").strip()
            if face_owner:
                break
            else:
                print("âŒ åç§°ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥ï¼")
        except (EOFError, KeyboardInterrupt):
            print("\nç¨‹åºè¢«ç”¨æˆ·å–æ¶ˆ")
            release_camera(camera, camera_type)
            return
    
    print(f"âœ… è¾“å…¥çš„äººè„¸æ‹¥æœ‰è€…åç§°ï¼š{face_owner}")
    
    # æ˜¾ç¤ºä¿å­˜ä½ç½®ä¿¡æ¯
    import os
    current_dir = os.path.dirname(os.path.abspath(__file__))
    save_path = os.path.join(current_dir, "face_identification", "dataset", face_owner)
    print(f"ðŸ“ äººè„¸å›¾åƒå°†ä¿å­˜åˆ°ï¼š{save_path}")
    print(f"ðŸ’¾ æ–‡ä»¶æ ¼å¼ï¼š000.jpg, 001.jpg, 002.jpg, ...")
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if os.path.exists(save_path):
        existing_files = [f for f in os.listdir(save_path) if f.endswith('.jpg')]
        if existing_files:
            print(f"âš ï¸  ç›®å½•å·²å­˜åœ¨ï¼ŒåŒ…å« {len(existing_files)} ä¸ªçŽ°æœ‰æ–‡ä»¶")
            overwrite = input("æ˜¯å¦è¦è¦†ç›–çŽ°æœ‰æ•°æ®ï¼Ÿ(y/N)ï¼š").strip().lower()
            if overwrite != 'y':
                print("ç”¨æˆ·å–æ¶ˆæ“ä½œ")
                release_camera(camera, camera_type)
                return
        else:
            print("ðŸ“‚ ç›®å½•å­˜åœ¨ä½†ä¸ºç©º")
    else:
        print("ðŸ“‚ å°†åˆ›å»ºæ–°ç›®å½•")
    
    print("\nç­‰å¾…3ç§’åŽå¼€å§‹é‡‡é›†...")
    import time
    for i in range(3, 0, -1):
        print(f"â° {i} ç§’...")
        time.sleep(1)
    
    # é…ç½®å‚æ•°
    N = 100  # éœ€è¦æ•æ‰çš„äººè„¸å›¾åƒæ•°é‡
    STRIDE = 5  # æ¯éš”å¤šå°‘å¸§æ•æ‰ä¸€æ¬¡äººè„¸å›¾åƒ
    EXPAND_FACTOR = 0.2  # å‡å°‘æ‰©å±•å› å­ï¼Œé¿å…è¾¹ç•Œé—®é¢˜
    
    # è®¡æ•°å™¨å’Œå­˜å‚¨
    count = 0
    taked_faces = []
    frame_count = 0
    
    print(f"\nå¼€å§‹é‡‡é›† {face_owner} çš„äººè„¸æ•°æ®...")
    print(f"ç›®æ ‡ï¼šé‡‡é›† {N} å¼ äººè„¸å›¾åƒ")
    print("æŽ§åˆ¶è¯´æ˜Ž:")
    print("- æŒ‰ 'q' é€€å‡º")
    print("- æŒ‰ 's' æ‰‹åŠ¨ä¿å­˜å½“å‰äººè„¸")
    print("- è¯·ä¿æŒäººè„¸åœ¨æ‘„åƒå¤´å‰å¹¶å˜æ¢è§’åº¦\n")

    try:
        while True:
            ret, frame = get_frame_from_camera(camera, camera_type)
            if not ret:
                print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
                break
            
            frame_count += 1
            
            try:
                # ç›´æŽ¥ä½¿ç”¨äººè„¸æ£€æµ‹ï¼Œè€Œä¸æ˜¯äººè„¸è¯†åˆ«
                # å› ä¸ºåœ¨é‡‡é›†é˜¶æ®µï¼Œç”¨æˆ·çš„äººè„¸æ•°æ®è¿˜ä¸å­˜åœ¨
                face_detected, face_region, detection_confidence = detect_face_simple(frame, estimator.detector, EXPAND_FACTOR)
                
                # æ˜¾ç¤ºä¸»çª—å£
                display_frame = frame.copy()
                
                # æ·»åŠ ä¿¡æ¯æ–‡æœ¬
                info_text = f"Collected: {len(taked_faces)}/{N}"
                cv2.putText(display_frame, info_text, (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                
                if face_detected:
                    status_text = f"Face detected! Confidence: {detection_confidence:.2f}"
                    color = (0, 255, 0)
                    
                    # åœ¨åŽŸå›¾ä¸Šç”»å‡ºæ£€æµ‹åˆ°çš„äººè„¸æ¡†
                    if face_region is not None:
                        # ç®€å•åœ°åœ¨åŽŸå›¾ä¸Šç”»ä¸ªç»¿æ¡†è¡¨ç¤ºæ£€æµ‹åˆ°äººè„¸
                        h, w = display_frame.shape[:2]
                        cv2.rectangle(display_frame, (w//4, h//4), (3*w//4, 3*h//4), (0, 255, 0), 3)
                else:
                    status_text = "No face detected"
                    color = (0, 0, 255)
                
                cv2.putText(display_frame, status_text, (10, 70), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
                
                # æ·»åŠ å¸§è®¡æ•°
                cv2.putText(display_frame, f"Frame: {frame_count}", (10, display_frame.shape[0] - 20), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                cv2.imshow(window_names['main'], display_frame)
                
                # å¦‚æžœæ£€æµ‹åˆ°äººè„¸ï¼Œæ˜¾ç¤ºå¹¶ä¿å­˜
                if face_detected and face_region is not None:
                    cv2.imshow(window_names['face'], face_region)
                    
                    # æŒ‰é—´éš”ä¿å­˜äººè„¸
                    if count % STRIDE == 0:
                        taked_faces.append(face_region)
                        print(f"é‡‡é›†è¿›åº¦: {len(taked_faces)}/{N} ({len(taked_faces)/N*100:.1f}%)")
                    
                    count += 1
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆé‡‡é›†
                if len(taked_faces) >= N:
                    print(f"\nâœ… é‡‡é›†å®Œæˆï¼å…±é‡‡é›† {len(taked_faces)} å¼ äººè„¸å›¾åƒ")
                    break
                
            except Exception as e:
                print(f"å¤„ç†å¸§æ—¶å‡ºé”™: {e}")
                # å³ä½¿å‡ºé”™ä¹Ÿæ˜¾ç¤ºåŽŸå§‹å¸§
                cv2.imshow(window_names['main'], frame)
            
            # é”®ç›˜æŽ§åˆ¶
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                print(f"\nç”¨æˆ·é€€å‡ºï¼Œå·²é‡‡é›† {len(taked_faces)} å¼ å›¾åƒ")
                break
            elif key == ord('s') and face_detected:
                # æ‰‹åŠ¨ä¿å­˜å½“å‰äººè„¸
                if face_region is not None:
                    taked_faces.append(face_region)
                    print(f"æ‰‹åŠ¨ä¿å­˜: {len(taked_faces)}/{N}")

    except KeyboardInterrupt:
        print(f"\nç¨‹åºè¢«ä¸­æ–­ï¼Œå·²é‡‡é›† {len(taked_faces)} å¼ å›¾åƒ")
    
    finally:
        release_camera(camera, camera_type)
    
    # ä¿å­˜é‡‡é›†çš„äººè„¸
    if len(taked_faces) > 0:
        print(f"\nðŸ’¾ æ­£åœ¨ä¿å­˜ {len(taked_faces)} å¼ äººè„¸å›¾åƒ...")
        
        try:
            # ç›´æŽ¥åœ¨è¿™é‡Œå®žçŽ°ä¿å­˜é€»è¾‘ï¼Œé¿å…å¤–éƒ¨å‡½æ•°é—®é¢˜
            save_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 
                                  "face_identification", "dataset", face_owner)
            
            # åˆ›å»ºç›®å½•
            os.makedirs(save_dir, exist_ok=True)
            
            # æ¸…ç©ºç›®å½•ï¼ˆå¦‚æžœæœ‰æ—§æ–‡ä»¶ï¼‰
            for file in os.listdir(save_dir):
                if file.endswith('.jpg'):
                    os.remove(os.path.join(save_dir, file))
            
            # ä¿å­˜æ–°æ–‡ä»¶
            saved_count = 0
            for i, face_img in enumerate(taked_faces):
                filename = os.path.join(save_dir, f"{str(i).zfill(3)}.jpg")
                if cv2.imwrite(filename, face_img):
                    saved_count += 1
                else:
                    print(f"âš ï¸ ä¿å­˜å¤±è´¥: {filename}")
            
            # æ˜¾ç¤ºè¯¦ç»†çš„ä¿å­˜ä¿¡æ¯
            print(f"âœ… äººè„¸å›¾åƒä¿å­˜æˆåŠŸï¼")
            print(f"ðŸ“ ä¿å­˜ä½ç½®ï¼š{save_dir}")
            print(f"ðŸ“‹ ä¿å­˜è¯¦æƒ…ï¼š")
            print(f"   - æ€»æ–‡ä»¶æ•°ï¼š{saved_count} å¼ ")
            print(f"   - æ–‡ä»¶åæ ¼å¼ï¼š000.jpg ~ {str(len(taked_faces)-1).zfill(3)}.jpg")
            print(f"   - æ–‡ä»¶å¤§å°ï¼šçº¦ {saved_count * 20} KB") 
            
            # éªŒè¯æ–‡ä»¶æ˜¯å¦çœŸçš„ä¿å­˜äº†
            if os.path.exists(save_dir):
                saved_files = [f for f in os.listdir(save_dir) if f.endswith('.jpg')]
                print(f"âœ“ éªŒè¯ï¼šå®žé™…ä¿å­˜äº† {len(saved_files)} ä¸ªæ–‡ä»¶")
                
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            print("ðŸ’¡ å»ºè®®ï¼šæ£€æŸ¥ç£ç›˜ç©ºé—´å’Œæ–‡ä»¶æƒé™")
    else:
        print("âš ï¸ æ²¡æœ‰é‡‡é›†åˆ°ä»»ä½•äººè„¸å›¾åƒï¼Œæ— éœ€ä¿å­˜")
    
    print("\nðŸŽ‰ ç¨‹åºç»“æŸ")

def detect_face_simple(frame, detector, expand_factor):
    """
    ç®€å•çš„äººè„¸æ£€æµ‹å‡½æ•°ï¼Œè¿”å›žæ˜¯å¦æ£€æµ‹åˆ°äººè„¸ã€äººè„¸åŒºåŸŸå’Œç½®ä¿¡åº¦
    """
    try:
        # è°ƒæ•´å›¾åƒå¤§å°
        (h, w) = frame.shape[:2]
        
        # æž„å»ºblobè¿›è¡Œäººè„¸æ£€æµ‹
        imageBlob = cv2.dnn.blobFromImage(
            cv2.resize(frame, (300, 300)), 1.0, (300, 300),
            (104.0, 177.0, 123.0), swapRB=False, crop=False)
        
        # è¿›è¡Œäººè„¸æ£€æµ‹
        detector.setInput(imageBlob)
        detections = detector.forward()
        
        # å¯»æ‰¾æœ€ä½³æ£€æµ‹ç»“æžœ
        best_detection = None
        best_confidence = 0
        
        for i in range(0, detections.shape[2]):
            confidence = detections[0, 0, i, 2]
            if confidence > 0.5 and confidence > best_confidence:
                best_confidence = confidence
                best_detection = detections[0, 0, i, 3:7]
        
        if best_detection is not None:
            # è®¡ç®—è¾¹ç•Œæ¡†åæ ‡
            box = best_detection * np.array([w, h, w, h])
            (startX, startY, endX, endY) = box.astype("int")
            
            # æ‰©å±•è¾¹ç•Œæ¡†
            fH, fW = endY - startY, endX - startX
            startX = int(max(0, startX - fW * expand_factor))
            endX = int(min(w, endX + fW * expand_factor))
            startY = int(max(0, startY - fH * expand_factor))
            endY = int(min(h, endY + fH * expand_factor))
            
            # æå–äººè„¸åŒºåŸŸ
            face = frame[startY:endY, startX:endX]
            
            # ç¡®ä¿äººè„¸åŒºåŸŸæœ‰æ•ˆ
            if face.shape[0] > 20 and face.shape[1] > 20:
                return True, face, best_confidence
        
        return False, None, 0.0
    
    except Exception as e:
        print(f"äººè„¸æ£€æµ‹æ—¶å‡ºé”™: {e}")
        return False, None, 0.0

if __name__ == "__main__":
    main()
